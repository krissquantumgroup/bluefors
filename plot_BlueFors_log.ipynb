{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this first."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 1,
>>>>>>> 8ffa19d78399140cf9b0d67ddc52cb34a0064e98
   "metadata": {
    "code_folding": [
     45,
     67,
     124,
     136,
     168,
     183,
     197
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
<<<<<<< HEAD
    "backend = \"Qt5Agg\"\n",
    "backend = \"Tkagg\"\n",
=======
    "# backend = \"Qt5Agg\"\n",
    "backend = \"TKAgg\"\n",
>>>>>>> 8ffa19d78399140cf9b0d67ddc52cb34a0064e98
    "matplotlib.use(backend) # set matplotlib backend\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "import textwrap\n",
    "\n",
<<<<<<< HEAD
    "logFolder = r'Z:\\logs\\BF2\\Logfiles'\n",
    "# logFolder = r'/home/jaseung/Downloads/logfiles'\n",
=======
    "logFolder = r'X:\\logs\\BF1'\n",
    "logFolder = r'X:\\logs\\BF2\\Logfiles'\n",
>>>>>>> 8ffa19d78399140cf9b0d67ddc52cb34a0064e98
    "\n",
    "def load_temperature_oneday(date:date):\n",
    "    \"\"\"\n",
    "        Read temperature log files and return two pandas dataframe of datetime and temperatures.\n",
    "    \"\"\"\n",
    "    \n",
    "    date_str = date.strftime(\"%y-%m-%d\")\n",
    "    base_path = os.path.join(logFolder, date_str)    \n",
    "    file_names = ['CH1 T ' + date_str + '.log', \n",
    "                  'CH2 T ' + date_str + '.log', \n",
    "                  'CH5 T ' + date_str + '.log', \n",
    "                  'CH6 T ' + date_str + '.log' ]\n",
    "\n",
    "    full_file_names = [ os.path.join(base_path, file_name) for file_name in file_names ]\n",
    "\n",
    "    df_datetimes, df_temperatures = pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    for file_name in full_file_names:\n",
    "        with open(file_name, 'r') as f: \n",
    "            df = pd.read_csv(f, names=['date', 'time', 'temperature'], header=0)\n",
    "            try:\n",
    "                df_datetime  = pd.to_datetime(df['date'] + df['time'], format=' %d-%m-%y%H:%M:%S')\n",
    "            except ValueError:\n",
    "                df_datetime  = pd.to_datetime(df['date'] + df['time'], format='%d-%m-%y%H:%M:%S')\n",
    "            df_datetimes = pd.concat([df_datetimes, df_datetime], axis=1)             \n",
    "            df_temperatures = pd.concat([df_temperatures, df['temperature']], axis=1)\n",
    "           \n",
    "#     print(df_datetimes.shape)\n",
    "#     print(df_temperatures.shape)   \n",
    "    \n",
    "    return df_datetimes, df_temperatures\n",
    "\n",
    "def load_pressure_oneday(date:date):\n",
    "    \"\"\"\n",
    "        Read pressure log file and return two pandas dataframe of datetime and pressure.\n",
    "    \"\"\"\n",
    "    date_str = date.strftime(\"%y-%m-%d\")\n",
    "    base_path = os.path.join(logFolder, date_str)  \n",
    "    file_name = 'maxigauge ' + date_str + '.log'\n",
    "    full_file_name = os.path.join(base_path, file_name)\n",
    "\n",
    "    df_datetimes, df_pressures = pd.DataFrame(), pd.DataFrame()\n",
    "    with open(full_file_name, 'r') as f:\n",
    "        df = pd.read_csv(f, header=None)\n",
    "        try:\n",
    "            df_datetimes  = pd.to_datetime(df.iloc[:,0] + df.iloc[:,1], format='%d-%m-%y%H:%M:%S')\n",
    "        except ValueError:\n",
    "            df_datetimes  = pd.to_datetime(df.iloc[:,0] + df.iloc[:,1], format=' %d-%m-%y%H:%M:%S')\n",
    "        df_pressures = df.iloc[:, [5,11,17,23,29,35]]\n",
    "       \n",
    "    # print(df_datetimes.shape)\n",
    "    # print(df_pressures.shape)   \n",
    "\n",
    "    return df_datetimes, df_pressures\n",
    "\n",
    "def load_flowmeter_oneday(date: date):\n",
    "    \"\"\"\n",
    "        Read flowmeter log file and return two pandas dataframe of datetime and flowrate.\n",
    "    \"\"\"\n",
    "    date_str = date.strftime(\"%y-%m-%d\")\n",
    "    base_path = os.path.join(logFolder, date_str)  \n",
    "    file_name = 'Flowmeter ' + date_str + '.log'\n",
    "    full_file_name = os.path.join(base_path, file_name)\n",
    "\n",
    "    df_datetimes, df_flowmeter = pd.DataFrame(), pd.DataFrame()\n",
    "    with open(full_file_name, 'r') as f:\n",
    "        df = pd.read_csv(f, header=None)\n",
    "        try:\n",
    "            df_datetimes  = pd.to_datetime(df.iloc[:,0] + df.iloc[:,1], format=' %d-%m-%y%H:%M:%S')\n",
    "        except ValueError:\n",
    "            df_datetimes  = pd.to_datetime(df.iloc[:,0] + df.iloc[:,1], format='%d-%m-%y%H:%M:%S')\n",
    "        df_flowmeter = df.iloc[:,2]\n",
    "       \n",
    "    # print(df_datetimes.shape)\n",
    "    # print(df_flowmeter.shape)   \n",
    "\n",
    "    return df_datetimes, df_flowmeter\n",
    "\n",
    "def load_status_oneday(date:date):\n",
    "    \"\"\"\n",
    "    Read status log file and return two pandas dataframe of datetime and status.\n",
    "    \"\"\"\n",
    "    date_str = date.strftime(\"%y-%m-%d\")\n",
    "    base_path = os.path.join(logFolder, date_str)  \n",
    "    file_name = 'Status_' + date_str + '.log'\n",
    "    full_file_name = os.path.join(base_path, file_name)\n",
    "\n",
    "    df_datetimes, df_status = pd.DataFrame(), pd.DataFrame()\n",
    "    with open(full_file_name, 'r') as f:\n",
    "        df = pd.read_csv(f, header=None)\n",
<<<<<<< HEAD
    "        df_datetimes  = pd.to_datetime(df.iloc[:,0] + df.iloc[:,1], format='%d-%m-%y%H:%M:%S')\n",
    "        _, column = df.shape\n",
    "        df_status = df.iloc[:, list(np.arange(3, column,2))]\n",
=======
    "        try:\n",
    "            df_datetimes  = pd.to_datetime(df.iloc[:,0] + df.iloc[:,1], format='%d-%m-%y%H:%M:%S')\n",
    "        except ValueError:\n",
    "            df_datetimes  = pd.to_datetime(df.iloc[:,0] + df.iloc[:,1], format=' %d-%m-%y%H:%M:%S')\n",
    "        df_status = df.iloc[:, list(np.arange(3,51,2))]\n",
>>>>>>> 8ffa19d78399140cf9b0d67ddc52cb34a0064e98
    "        \n",
    "    # print(df_datetimes.shape)\n",
    "    # print(df_pressures.shape)   \n",
    "\n",
    "    return df_datetimes, df_status\n",
    "\n",
    "\n",
    "def load_temperature(start_date:date, end_date:date):\n",
    "    \"\"\"\n",
    "    Return time and temperature dataframes between start_date and end_date\n",
    "    \"\"\"\n",
    "    df_datetimes_all, df_temperatures_all = pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    while start_date <= end_date:\n",
    "        \n",
    "        try:\n",
    "            df_datetimes, df_temperatures = load_temperature_oneday(start_date)\n",
    "        except FileNotFoundError:\n",
    "            df_datetimes, df_temperatures = pd.DataFrame(), pd.DataFrame()\n",
    "            print(f\"FileNotFound: {start_date}, temperature\")\n",
    "\n",
    "        df_datetimes_all = pd.concat([df_datetimes_all, df_datetimes], axis=0)\n",
    "        df_temperatures_all = pd.concat([df_temperatures_all, df_temperatures], axis=0)\n",
    "        \n",
    "        start_date += timedelta(days=1)\n",
    "    \n",
    "    return df_datetimes_all, df_temperatures_all\n",
    "        \n",
    "def load_pressure(start_date:date, end_date:date):\n",
    "    \"\"\"\n",
    "    Return time and pressure dataframes between start_date and end_date\n",
    "    \"\"\"\n",
    "    df_datetimes_all, df_pressures_all = pd.DataFrame(), pd.DataFrame()\n",
    "    while start_date <= end_date:\n",
    "        try:\n",
    "            df_datetimes, df_pressures = load_pressure_oneday(start_date)\n",
    "        except FileNotFoundError:\n",
    "            df_datetimes, df_pressures = pd.DataFrame(), pd.DataFrame()\n",
    "            print(f\"FileNotFound: {start_date}, pressure\")\n",
    "\n",
    "        df_datetimes_all = pd.concat([df_datetimes_all, df_datetimes], axis=0)\n",
    "        df_pressures_all = pd.concat([df_pressures_all, df_pressures], axis=0)\n",
    "        \n",
    "        start_date += timedelta(days=1)\n",
    "    \n",
    "    return df_datetimes_all, df_pressures_all\n",
    "\n",
    "def load_flowmeter(start_date: date, end_date: date):\n",
    "    \"\"\"\n",
    "    Return time and flowmeter dataframes between start_date and end_date\n",
    "    \"\"\"\n",
    "    df_datetimes_all, df_flowmeters_all = pd.DataFrame(), pd.DataFrame()\n",
    "    while start_date <= end_date:\n",
    "        try:\n",
    "            df_datetimes, df_flowmeters = load_flowmeter_oneday(start_date)\n",
    "        except FileNotFoundError:\n",
    "            df_datetimes, df_flowmeters = pd.DataFrame(), pd.DataFrame()\n",
    "            print(f\"FileNotFound: {start_date}, flowmeter\")\n",
    "    \n",
    "        df_datetimes_all = pd.concat([df_datetimes_all, df_datetimes], axis=0)\n",
    "        df_flowmeters_all = pd.concat([df_flowmeters_all, df_flowmeters], axis=0)\n",
    "        \n",
    "        start_date += timedelta(days=1)\n",
    "    \n",
    "    return df_datetimes_all, df_flowmeters_all\n",
    "\n",
    "def load_status(start_date:date, end_date:date):\n",
    "    \"\"\"\n",
    "    Return time and status dataframes between start_date and end_date\n",
    "    \"\"\"\n",
    "    df_datetimes_all, df_status_all = pd.DataFrame(), pd.DataFrame()\n",
    "    while start_date <= end_date:\n",
    "        try:\n",
    "            df_datetimes, df_status = load_status_oneday(start_date)\n",
    "        except FileNotFoundError:\n",
    "            df_datetimes, df_status = pd.DataFrame(), pd.DataFrame()\n",
    "            print(f\"FileNotFound: {start_date}, status\")\n",
    "\n",
    "        df_datetimes_all = pd.concat([df_datetimes_all, df_datetimes], axis=0)\n",
    "        df_status_all = pd.concat([df_status_all, df_status], axis=0)\n",
    "        \n",
    "        start_date += timedelta(days=1)\n",
    "    \n",
    "    return df_datetimes_all, df_status_all\n",
    "\n",
    "\n",
    "def plot_temperature(start_date: date, end_date: date, yscale='linear'):\n",
    "    \"\"\"\n",
    "    Plot temperature.\n",
    "    \"\"\"\n",
    "    df_df_datetimes_all, df_temperatures_all = load_temperature(start_date, end_date)\n",
    "\n",
    "    if df_temperatures_all.size == 0:\n",
    "        print(\"No temperature data available!\")\n",
    "        return\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    text = \"Temperature from \" + start_date.strftime(\"%y-%m-%d\") + \" to \" + end_date.strftime(\"%y-%m-%d\")\n",
    "    title = \"Click on legend line to toggle line on/off\" + \"\\n\" + \"\\n\".join(textwrap.wrap(text, 60))\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Datetime')\n",
    "    ax.set_ylabel('Temperature(K)')\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.grid()\n",
    "    \n",
    "    line1, = ax.plot(df_df_datetimes_all.iloc[:,0], df_temperatures_all.iloc[:,0], '.-',label=\"50 K\")\n",
    "    line2, = ax.plot(df_df_datetimes_all.iloc[:,1], df_temperatures_all.iloc[:,1], label=\"4 K\")\n",
    "    line3, = ax.plot(df_df_datetimes_all.iloc[:,2], df_temperatures_all.iloc[:,2], label=\"Still\")\n",
    "    line4, = ax.plot(df_df_datetimes_all.iloc[:,3], df_temperatures_all.iloc[:,3], label=\"MCX\")\n",
    "    leg = ax.legend(fancybox=True, shadow=True)\n",
    "    \n",
    "    lines = [line1, line2, line3, line4]\n",
    "    lined = {}  # Will map legend lines to original lines.\n",
    "    for legline, origline in zip(leg.get_lines(), lines):\n",
    "        legline.set_picker(True)  # Enable picking on the legend line.\n",
    "        lined[legline] = origline\n",
    "    \n",
    "    def on_pick(event):\n",
    "        # On the pick event, find the original line corresponding to the legend\n",
    "        # proxy line, and toggle its visibility.\n",
    "        legline = event.artist\n",
    "        origline = lined[legline]\n",
    "        visible = not origline.get_visible()\n",
    "        origline.set_visible(visible)\n",
    "        # Change the alpha on the line in the legend so we can see what lines\n",
    "        # have been toggled.\n",
    "        legline.set_alpha(1.0 if visible else 0.2)\n",
    "        fig.canvas.draw()\n",
    "\n",
    "    fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "    plt.show(block=False)\n",
    "\n",
    "    return fig, ax   \n",
    "\n",
    "def plot_pressure(start_date: date, end_date: date, yscale='linear'):\n",
    "    \"\"\"\n",
    "    Plot pressure\n",
    "    \"\"\"\n",
    "    df_datetimes_all, df_pressures_all = load_pressure(start_date, end_date)\n",
    "\n",
    "    if df_pressures_all.size == 0:\n",
    "        print(\"No pressure data available!\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    text = \"Pressures from \" + start_date.strftime(\"%y-%m-%d\") + \" to \" + end_date.strftime(\"%y-%m-%d\")\n",
    "    title = \"Click on legend line to toggle line on/off\" + \"\\n\" + \"\\n\".join(textwrap.wrap(text, 60))\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Datetime')\n",
    "    ax.set_ylabel('Pressure (mBar)')\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.grid()\n",
    "    \n",
    "    line1, = ax.plot(df_datetimes_all, df_pressures_all.iloc[:,0], label=\"P1\")\n",
    "    line2, = ax.plot(df_datetimes_all, df_pressures_all.iloc[:,1], label=\"P2\")\n",
    "    line3, = ax.plot(df_datetimes_all, df_pressures_all.iloc[:,2], label=\"P3\")\n",
    "    line4, = ax.plot(df_datetimes_all, df_pressures_all.iloc[:,3], label=\"P4\")\n",
    "    line5, = ax.plot(df_datetimes_all, df_pressures_all.iloc[:,4], label=\"P5\")\n",
    "    line6, = ax.plot(df_datetimes_all, df_pressures_all.iloc[:,5], label=\"P6\")\n",
    "    leg = ax.legend(fancybox=True, shadow=True)\n",
    "    \n",
    "    lines = [line1, line2, line3, line4, line5, line6]\n",
    "    lined = {}  # Will map legend lines to original lines.\n",
    "    for legline, origline in zip(leg.get_lines(), lines):\n",
    "        legline.set_picker(True)  # Enable picking on the legend line.\n",
    "        lined[legline] = origline\n",
    "    \n",
    "    def on_pick(event):\n",
    "        # On the pick event, find the original line corresponding to the legend\n",
    "        # proxy line, and toggle its visibility.\n",
    "        legline = event.artist\n",
    "        origline = lined[legline]\n",
    "        visible = not origline.get_visible()\n",
    "        origline.set_visible(visible)\n",
    "        # Change the alpha on the line in the legend so we can see what lines\n",
    "        # have been toggled.\n",
    "        legline.set_alpha(1.0 if visible else 0.2)\n",
    "        fig.canvas.draw()\n",
    "\n",
    "    fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "    plt.show(block=False)\n",
    "\n",
    "def plot_flowmeter(start_date: date, end_date: date):\n",
    "    \"\"\"\n",
    "    Plot flowmeter.\n",
    "    \"\"\"\n",
    "    df_datetimes_all, df_flowmeters_all = load_flowmeter(start_date, end_date)\n",
    "\n",
    "    if df_flowmeters_all.size == 0:\n",
    "        print(\"No flowmeter data available!\")\n",
    "        return\n",
    "        \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    text = \"Flowmeter from \" + start_date.strftime(\"%y-%m-%d\") + \" to \" + end_date.strftime(\"%y-%m-%d\")\n",
    "    title = \"Click on legend line to toggle line on/off\" + \"\\n\" + \"\\n\".join(textwrap.wrap(text, 60))\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Datetime')\n",
    "    ax.set_ylabel('Flowrate (mmol/s)')\n",
    "    ax.grid()\n",
    "    \n",
    "    line1, = ax.plot(df_datetimes_all, df_flowmeters_all.iloc[:,0], label=\"Flowmeter\")\n",
    "    leg = ax.legend(fancybox=True, shadow=True)\n",
    "    plt.show(block=False)\n",
    "\n",
    "def plot_status(start_date: date, end_date: date, yscale='linear'):\n",
    "    \"\"\"\n",
    "    Plot status.\n",
    "    \"\"\"\n",
    "    df_datetimes_all, df_status_all = load_status(start_date, end_date)\n",
    "\n",
    "    if df_status_all.size == 0:\n",
    "        print(\"No status data available!\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    text = \"Status from \" + start_date.strftime(\"%y-%m-%d\") + \" to \" + end_date.strftime(\"%y-%m-%d\")\n",
    "    title = \"Click on legend line to toggle line on/off\" + \"\\n\" + \"\\n\".join(textwrap.wrap(text, 60))\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Datetime')\n",
    "    ax.set_ylabel('Status')\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.grid()\n",
    "    \n",
    "\n",
    "    s = \"01-01-22,00:14:17,cptempwi,1.450000E+1,cptempwo,2.480000E+1,cptemph,7.050000E+1,cptempo,3.090000E+1,cpttime,2.548976E+6,cperrcode,2.800000E+1,cpavgl,8.840000E+1,cpavgh,2.748000E+2,nxdsf,3.000000E+1,nxdsct,4.100000E+1,nxdst,4.910500E+4,nxdsbs,4.050300E+4,nxdstrs,2.185700E+4,tc400remoteprio,1.000000E+0,tc400spdswptatt,1.000000E+0,tc400errorcode,0.000000E+0,tc400ovtempelec,0.000000E+0,tc400ovtemppump,0.000000E+0,tc400setspdatt,1.000000E+0,tc400pumpaccel,0.000000E+0,tc400heating,0.000000E+0,tc400standby,0.000000E+0,tc400pumpstatn,1.000000E+0,tc400commerr,0.000000E+0\"\n",
    "    legend_labels = s.split(',')[2::2]\n",
    "    \n",
    "    lines = []\n",
    "    _, column = df_status_all.shape\n",
    "    for i in range(column):\n",
    "        line, = ax.plot(df_datetimes_all, df_status_all.iloc[:,i], label=legend_labels[i])\n",
    "        lines.append(line)\n",
    "\n",
    "    leg = ax.legend(fancybox=True, shadow=True)\n",
    "    \n",
    "    lined = {}  # Will map legend lines to original lines.\n",
    "    for legline, origline in zip(leg.get_lines(), lines):\n",
    "        legline.set_picker(True)  # Enable picking on the legend line.\n",
    "        lined[legline] = origline\n",
    "    \n",
    "    def on_pick(event):\n",
    "        # On the pick event, find the original line corresponding to the legend\n",
    "        # proxy line, and toggle its visibility.\n",
    "        legline = event.artist\n",
    "        origline = lined[legline]\n",
    "        visible = not origline.get_visible()\n",
    "        origline.set_visible(visible)\n",
    "        # Change the alpha on the line in the legend so we can see what lines\n",
    "        # have been toggled.\n",
    "        legline.set_alpha(1.0 if visible else 0.2)\n",
    "        fig.canvas.draw()\n",
    "\n",
    "    fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "    plt.show(block=False)\n",
    "\n",
    "def plot_temperature_pressure_flowmeter(start_date:date, end_date:date, yscale='linear'):\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3,1, sharex=True)\n",
    "    \n",
    "    # temperature\n",
    "    df_df_datetimes_all, df_temperatures_all = load_temperature(start_date, end_date)\n",
    "    \n",
    "    if df_temperatures_all.size == 0:\n",
    "        print(\"No temperature data available!\")\n",
    "    else:\n",
    "        title = \"Click on legend line to toggle line on/off\" \n",
    "        ax1.set_title(title)\n",
    "    #     ax1.set_xlabel('Datetime')\n",
    "        ax1.set_ylabel('Temperature(K)')\n",
    "        ax1.set_yscale(yscale)\n",
    "        ax1.grid()\n",
    "        \n",
    "        line1, = ax1.plot(df_df_datetimes_all.iloc[:,0], df_temperatures_all.iloc[:,0], label=\"50 K\")\n",
    "        line2, = ax1.plot(df_df_datetimes_all.iloc[:,1], df_temperatures_all.iloc[:,1], label=\"4 K\")\n",
    "        line3, = ax1.plot(df_df_datetimes_all.iloc[:,2], df_temperatures_all.iloc[:,2], label=\"Still\")\n",
    "        line4, = ax1.plot(df_df_datetimes_all.iloc[:,3], df_temperatures_all.iloc[:,3], label=\"MCX\")\n",
    "        leg1 = ax1.legend(fancybox=True, shadow=True)\n",
    "    \n",
    "    # pressure\n",
    "    df_datetimes_all, df_pressures_all = load_pressure(start_date, end_date)\n",
    "   \n",
    "    if df_pressures_all.size == 0:\n",
    "        print(\"No pressure data available!\")\n",
    "    else:\n",
    "    #     ax2.set_xlabel('Datetime')\n",
    "        ax2.set_ylabel('Pressure (mBar)')\n",
    "        ax2.set_yscale(yscale)\n",
    "        ax2.grid()\n",
    "        \n",
    "        line11, = ax2.plot(df_datetimes_all, df_pressures_all.iloc[:,0], label=\"P1\")\n",
    "        line12, = ax2.plot(df_datetimes_all, df_pressures_all.iloc[:,1], label=\"P2\")\n",
    "        line13, = ax2.plot(df_datetimes_all, df_pressures_all.iloc[:,2], label=\"P3\")\n",
    "        line14, = ax2.plot(df_datetimes_all, df_pressures_all.iloc[:,3], label=\"P4\")\n",
    "        line15, = ax2.plot(df_datetimes_all, df_pressures_all.iloc[:,4], label=\"P5\")\n",
    "        line16, = ax2.plot(df_datetimes_all, df_pressures_all.iloc[:,5], label=\"P6\")\n",
    "        leg2 = ax2.legend(fancybox=True, shadow=True)\n",
    "\n",
    "    # flowmeter\n",
    "    df_datetimes_all, df_flowmeters_all = load_flowmeter(start_date, end_date)\n",
    "\n",
    "    if df_flowmeters_all.size == 0:\n",
    "        print(\"No pressure data available!\")\n",
    "    else:\n",
    "        ax3.set_xlabel('Datetime')\n",
    "        ax3.set_ylabel('Flowrate (mmol/s)')\n",
    "        ax3.grid()\n",
    "        \n",
    "        line21, = ax3.plot(df_datetimes_all, df_flowmeters_all.iloc[:,0], label=\"Flowmeter\")\n",
    "        leg3 = ax3.legend(fancybox=True, shadow=True)\n",
    "\n",
    "    plt.show(block=False)\n",
    "    \n",
    "def plot_temperature_pressure_flowmeter_status(start_date:date, end_date:date, yscale='linear'):\n",
    "\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(4,1,sharex=True)\n",
    "    \n",
    "    # temperature\n",
    "    df_df_datetimes_all, df_temperatures_all = load_temperature(start_date, end_date)\n",
    "    \n",
    "    if df_temperatures_all.size == 0:\n",
    "        print(\"No flowmeter data available!\")\n",
    "    else:\n",
    "        title = \"Click on legend line to toggle line on/off\" \n",
    "        ax1.set_title(title)\n",
    "    #     ax1.set_xlabel('Datetime')\n",
    "        ax1.set_ylabel('Temperature(K)')\n",
    "        ax1.set_yscale(yscale)\n",
    "        ax1.grid()\n",
    "        \n",
    "        line1, = ax1.plot(df_df_datetimes_all.iloc[:,0], df_temperatures_all.iloc[:,0], label=\"50 K\")\n",
    "        line2, = ax1.plot(df_df_datetimes_all.iloc[:,1], df_temperatures_all.iloc[:,1], label=\"4 K\")\n",
    "        line3, = ax1.plot(df_df_datetimes_all.iloc[:,2], df_temperatures_all.iloc[:,2], label=\"Still\")\n",
    "        line4, = ax1.plot(df_df_datetimes_all.iloc[:,3], df_temperatures_all.iloc[:,3], label=\"MCX\")\n",
    "        # leg1 = ax1.legend(fancybox=True, shadow=True)\n",
    "    \n",
    "    # pressure\n",
    "    df_datetimes_all, df_pressures_all = load_pressure(start_date, end_date)\n",
    "\n",
    "    if df_pressures_all.size == 0:\n",
    "        print(\"No flowmeter data available!\")\n",
    "    else:\n",
    "    #     ax2.set_xlabel('Datetime')\n",
    "        ax2.set_ylabel('Pressure (mBar)')\n",
    "        ax2.set_yscale(yscale)\n",
    "        ax2.grid()\n",
    "        \n",
    "        line11, = ax2.plot(df_datetimes_all, df_pressures_all.iloc[:,0], label=\"P1\")\n",
    "        line12, = ax2.plot(df_datetimes_all, df_pressures_all.iloc[:,1], label=\"P2\")\n",
    "        line13, = ax2.plot(df_datetimes_all, df_pressures_all.iloc[:,2], label=\"P3\")\n",
    "        line14, = ax2.plot(df_datetimes_all, df_pressures_all.iloc[:,3], label=\"P4\")\n",
    "        line15, = ax2.plot(df_datetimes_all, df_pressures_all.iloc[:,4], label=\"P5\")\n",
    "        line16, = ax2.plot(df_datetimes_all, df_pressures_all.iloc[:,5], label=\"P6\")\n",
    "        # leg2 = ax2.legend(fancybox=True, shadow=True)\n",
    "\n",
    "    # flowmeter\n",
    "    df_datetimes_all, df_flowmeters_all = load_flowmeter(start_date, end_date)\n",
    "    \n",
    "    if df_flowmeters_all.size == 0:\n",
    "        print(\"No flowmeter data available!\")\n",
    "    else:        \n",
    "    #     ax3.set_xlabel('Datetime')\n",
    "        ax3.set_ylabel('Flowrate (mmol/s)')\n",
    "        ax3.grid()\n",
    "        line21, = ax3.plot(df_datetimes_all, df_flowmeters_all.iloc[:,0], label=\"Flowmeter\")\n",
    "        # leg3 = ax3.legend(fancybox=True, shadow=True)\n",
    "\n",
    "        # status\n",
    "        df_datetimes_all, df_status_all = load_status(start_date, end_date)\n",
    "\n",
    "        ax4.set_xlabel('Datetime')\n",
    "        ax4.set_ylabel('Stauts')\n",
    "        ax4.set_yscale(yscale)\n",
    "        ax4.grid()\n",
    "\n",
    "        s = \"01-01-22,00:14:17,cptempwi,1.450000E+1,cptempwo,2.480000E+1,cptemph,7.050000E+1,cptempo,3.090000E+1,cpttime,2.548976E+6,cperrcode,2.800000E+1,cpavgl,8.840000E+1,cpavgh,2.748000E+2,nxdsf,3.000000E+1,nxdsct,4.100000E+1,nxdst,4.910500E+4,nxdsbs,4.050300E+4,nxdstrs,2.185700E+4,tc400remoteprio,1.000000E+0,tc400spdswptatt,1.000000E+0,tc400errorcode,0.000000E+0,tc400ovtempelec,0.000000E+0,tc400ovtemppump,0.000000E+0,tc400setspdatt,1.000000E+0,tc400pumpaccel,0.000000E+0,tc400heating,0.000000E+0,tc400standby,0.000000E+0,tc400pumpstatn,1.000000E+0,tc400commerr,0.000000E+0\"\n",
    "        legend_labels = s.split(',')[2::2]\n",
    "        _, column = df_status_all.shape\n",
    "        lines = []\n",
    "        for i in range(column):\n",
    "            line, = ax4.plot(df_datetimes_all, df_status_all.iloc[:,i], label=legend_labels[i])\n",
    "            lines.append(line)\n",
    "\n",
    "        leg = ax4.legend(fancybox=True, shadow=True)\n",
    "\n",
    "\n",
    "        lined = {}  # Will map legend lines to original lines.\n",
    "        for legline, origline in zip(leg.get_lines(), lines):\n",
    "            legline.set_picker(True)  # Enable picking on the legend line.\n",
    "            lined[legline] = origline\n",
    "    \n",
    "    def on_pick(event):\n",
    "        # On the pick event, find the original line corresponding to the legend\n",
    "        # proxy line, and toggle its visibility.\n",
    "        legline = event.artist\n",
    "        origline = lined[legline]\n",
    "        visible = not origline.get_visible()\n",
    "        origline.set_visible(visible)\n",
    "        # Change the alpha on the line in the legend so we can see what lines\n",
    "        # have been toggled.\n",
    "        legline.set_alpha(1.0 if visible else 0.2)\n",
    "        fig.canvas.draw()\n",
    "\n",
    "        fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "\n",
    "\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot BlueFors log"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileNotFound: 2023-05-31, temperature\n",
      "FileNotFound: 2023-06-01, temperature\n",
      "FileNotFound: 2023-06-02, temperature\n",
      "FileNotFound: 2023-06-03, temperature\n",
      "FileNotFound: 2023-06-04, temperature\n",
      "FileNotFound: 2023-06-05, temperature\n",
      "FileNotFound: 2023-06-06, temperature\n",
      "FileNotFound: 2023-06-07, temperature\n",
      "FileNotFound: 2023-06-08, temperature\n",
      "FileNotFound: 2023-05-31, pressure\n",
      "FileNotFound: 2023-06-01, pressure\n",
      "FileNotFound: 2023-06-02, pressure\n",
      "FileNotFound: 2023-06-03, pressure\n",
      "FileNotFound: 2023-06-04, pressure\n",
      "FileNotFound: 2023-06-05, pressure\n",
      "FileNotFound: 2023-06-06, pressure\n",
      "FileNotFound: 2023-06-07, pressure\n",
      "FileNotFound: 2023-06-08, pressure\n",
      "FileNotFound: 2023-04-22, flowmeter\n",
      "FileNotFound: 2023-04-23, flowmeter\n",
      "FileNotFound: 2023-04-24, flowmeter\n",
      "FileNotFound: 2023-04-25, flowmeter\n",
      "FileNotFound: 2023-04-26, flowmeter\n",
      "FileNotFound: 2023-04-27, flowmeter\n",
      "FileNotFound: 2023-04-28, flowmeter\n",
      "FileNotFound: 2023-04-29, flowmeter\n",
      "FileNotFound: 2023-04-30, flowmeter\n",
      "FileNotFound: 2023-05-01, flowmeter\n",
      "FileNotFound: 2023-05-02, flowmeter\n",
      "FileNotFound: 2023-05-03, flowmeter\n",
      "FileNotFound: 2023-05-04, flowmeter\n",
      "FileNotFound: 2023-05-05, flowmeter\n",
      "FileNotFound: 2023-05-06, flowmeter\n",
      "FileNotFound: 2023-05-07, flowmeter\n",
      "FileNotFound: 2023-05-08, flowmeter\n",
      "FileNotFound: 2023-05-09, flowmeter\n",
      "FileNotFound: 2023-05-10, flowmeter\n",
      "FileNotFound: 2023-05-11, flowmeter\n",
      "FileNotFound: 2023-05-12, flowmeter\n",
      "FileNotFound: 2023-05-13, flowmeter\n",
      "FileNotFound: 2023-05-14, flowmeter\n",
      "FileNotFound: 2023-05-15, flowmeter\n",
      "FileNotFound: 2023-05-16, flowmeter\n",
      "FileNotFound: 2023-05-17, flowmeter\n",
      "FileNotFound: 2023-05-18, flowmeter\n",
      "FileNotFound: 2023-05-19, flowmeter\n",
      "FileNotFound: 2023-05-20, flowmeter\n",
      "FileNotFound: 2023-05-21, flowmeter\n",
      "FileNotFound: 2023-05-22, flowmeter\n",
      "FileNotFound: 2023-05-23, flowmeter\n",
      "FileNotFound: 2023-05-24, flowmeter\n",
      "FileNotFound: 2023-05-25, flowmeter\n",
      "FileNotFound: 2023-05-26, flowmeter\n",
      "FileNotFound: 2023-05-27, flowmeter\n",
      "FileNotFound: 2023-05-28, flowmeter\n",
      "FileNotFound: 2023-05-29, flowmeter\n",
      "FileNotFound: 2023-05-30, flowmeter\n",
      "FileNotFound: 2023-05-31, flowmeter\n",
      "FileNotFound: 2023-06-01, flowmeter\n",
      "FileNotFound: 2023-06-02, flowmeter\n",
      "FileNotFound: 2023-06-03, flowmeter\n",
      "FileNotFound: 2023-06-04, flowmeter\n",
      "FileNotFound: 2023-06-05, flowmeter\n",
      "FileNotFound: 2023-06-06, flowmeter\n",
      "FileNotFound: 2023-06-07, flowmeter\n",
      "FileNotFound: 2023-06-08, flowmeter\n",
      "FileNotFound: 2023-06-09, flowmeter\n",
      "FileNotFound: 2023-06-10, flowmeter\n",
      "FileNotFound: 2023-06-11, flowmeter\n",
      "FileNotFound: 2023-06-12, flowmeter\n",
      "FileNotFound: 2023-06-13, flowmeter\n",
      "FileNotFound: 2023-06-14, flowmeter\n",
      "FileNotFound: 2023-06-15, flowmeter\n",
      "FileNotFound: 2023-06-16, flowmeter\n",
      "FileNotFound: 2023-06-17, flowmeter\n",
      "FileNotFound: 2023-06-18, flowmeter\n",
      "FileNotFound: 2023-06-19, flowmeter\n",
      "No flowmeter data available!\n"
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 2 fields in line 2, saw 44\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m yscale \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m \u001b[39m# 'linear' or 'log'\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# plot_temperature(start_date, end_date, yscale=yscale)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# plot_pressure(start_date, end_date, yscale=yscale)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# plot_flowmeter(start_date, end_date)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m plot_status(start_date, end_date, yscale\u001b[39m=\u001b[39;49myscale)\n\u001b[0;32m      9\u001b[0m \u001b[39m# plot_temperature_pressure_flowmeter(start_date, end_date, yscale=yscale)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m# plot_temperature_pressure_flowmeter_status(start_date, end_date, yscale=yscale)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 310\u001b[0m, in \u001b[0;36mplot_status\u001b[1;34m(start_date, end_date, yscale)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_status\u001b[39m(start_date: date, end_date: date, yscale\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    307\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39m    Plot status.\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     df_datetimes_all, df_status_all \u001b[39m=\u001b[39m load_status(start_date, end_date)\n\u001b[0;32m    312\u001b[0m     fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots()\n\u001b[0;32m    314\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mStatus from \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m start_date\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39my-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m to \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m end_date\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39my-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 184\u001b[0m, in \u001b[0;36mload_status\u001b[1;34m(start_date, end_date)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39mwhile\u001b[39;00m start_date \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m end_date:\n\u001b[0;32m    183\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m         df_datetimes, df_status \u001b[39m=\u001b[39m load_status_oneday(start_date)\n\u001b[0;32m    185\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m         df_datetimes, df_status \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(), pd\u001b[39m.\u001b[39mDataFrame()\n",
      "Cell \u001b[1;32mIn[1], line 105\u001b[0m, in \u001b[0;36mload_status_oneday\u001b[1;34m(date)\u001b[0m\n\u001b[0;32m    103\u001b[0m df_datetimes, df_status \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(), pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[0;32m    104\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(full_file_name, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m--> 105\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(f, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    106\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m         df_datetimes  \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df\u001b[39m.\u001b[39miloc[:,\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m df\u001b[39m.\u001b[39miloc[:,\u001b[39m1\u001b[39m], \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%\u001b[39m\u001b[39my\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jaseung\\myenv\\qm\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jaseung\\myenv\\qm\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jaseung\\myenv\\qm\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Jaseung\\myenv\\qm\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\Jaseung\\myenv\\qm\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1771\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1772\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     (\n\u001b[0;32m   1775\u001b[0m         index,\n\u001b[0;32m   1776\u001b[0m         columns,\n\u001b[0;32m   1777\u001b[0m         col_dict,\n\u001b[1;32m-> 1778\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1779\u001b[0m         nrows\n\u001b[0;32m   1780\u001b[0m     )\n\u001b[0;32m   1781\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Jaseung\\myenv\\qm\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m--> 230\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[0;32m    231\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    232\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mc:\\Users\\Jaseung\\myenv\\qm\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Jaseung\\myenv\\qm\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Jaseung\\myenv\\qm\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Jaseung\\myenv\\qm\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 2 fields in line 2, saw 44\n"
>>>>>>> 8ffa19d78399140cf9b0d67ddc52cb34a0064e98
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "start_date = date(2023,4,22)\n",
    "end_date   = date(2023,6,19)\n",
=======
    "start_date = date(2023,4,5)\n",
    "end_date   = date(2023,4,5)\n",
>>>>>>> 8ffa19d78399140cf9b0d67ddc52cb34a0064e98
    "\n",
    "yscale = 'linear' # 'linear' or 'log'\n",
    "# plot_temperature(start_date, end_date, yscale=yscale)\n",
    "# plot_pressure(start_date, end_date, yscale=yscale)\n",
    "# plot_flowmeter(start_date, end_date)\n",
    "# plot_status(start_date, end_date, yscale=yscale)\n",
    "# plot_temperature_pressure_flowmeter(start_date, end_date, yscale=yscale)\n",
    "# plot_temperature_pressure_flowmeter_status(start_date, end_date, yscale=yscale)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 4,
>>>>>>> 8ffa19d78399140cf9b0d67ddc52cb34a0064e98
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "'module://matplotlib_inline.backend_inline'"
      ]
     },
     "execution_count": 2,
=======
       "'TkAgg'"
      ]
     },
     "execution_count": 4,
>>>>>>> 8ffa19d78399140cf9b0d67ddc52cb34a0064e98
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.get_backend() # show current backend"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'' is not a valid value for backend; supported values are ['GTK3Agg', 'GTK3Cairo', 'GTK4Agg', 'GTK4Cairo', 'MacOSX', 'nbAgg', 'QtAgg', 'QtCairo', 'Qt5Agg', 'Qt5Cairo', 'TkAgg', 'TkCairo', 'WebAgg', 'WX', 'WXAgg', 'WXCairo', 'agg', 'cairo', 'pdf', 'pgf', 'ps', 'svg', 'template']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m matplotlib\u001b[39m.\u001b[39;49muse(\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Jaseung\\myenv\\qm\\lib\\site-packages\\matplotlib\\__init__.py:1247\u001b[0m, in \u001b[0;36muse\u001b[1;34m(backend, force)\u001b[0m\n\u001b[0;32m   1206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39muse\u001b[39m(backend, \u001b[39m*\u001b[39m, force\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \u001b[39m    Select the backend used for rendering and GUI integration.\u001b[39;00m\n\u001b[0;32m   1209\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \n\u001b[0;32m   1246\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     name \u001b[39m=\u001b[39m validate_backend(backend)\n\u001b[0;32m   1248\u001b[0m     \u001b[39m# don't (prematurely) resolve the \"auto\" backend setting\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m     \u001b[39mif\u001b[39;00m rcParams\u001b[39m.\u001b[39m_get_backend_or_none() \u001b[39m==\u001b[39m name:\n\u001b[0;32m   1250\u001b[0m         \u001b[39m# Nothing to do if the requested backend is already set\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jaseung\\myenv\\qm\\lib\\site-packages\\matplotlib\\rcsetup.py:252\u001b[0m, in \u001b[0;36mvalidate_backend\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_backend\u001b[39m(s):\n\u001b[0;32m    250\u001b[0m     backend \u001b[39m=\u001b[39m (\n\u001b[0;32m    251\u001b[0m         s \u001b[39mif\u001b[39;00m s \u001b[39mis\u001b[39;00m _auto_backend_sentinel \u001b[39mor\u001b[39;00m s\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmodule://\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 252\u001b[0m         \u001b[39melse\u001b[39;00m _validate_standard_backends(s))\n\u001b[0;32m    253\u001b[0m     \u001b[39mreturn\u001b[39;00m backend\n",
      "File \u001b[1;32mc:\\Users\\Jaseung\\myenv\\qm\\lib\\site-packages\\matplotlib\\rcsetup.py:82\u001b[0m, in \u001b[0;36mValidateInStrings.__call__\u001b[1;34m(self, s)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(s, \u001b[39mstr\u001b[39m)\n\u001b[0;32m     78\u001b[0m         \u001b[39mand\u001b[39;00m (s\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m s\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     79\u001b[0m              \u001b[39mor\u001b[39;00m s\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m s\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m     80\u001b[0m         \u001b[39mand\u001b[39;00m s[\u001b[39m1\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid):\n\u001b[0;32m     81\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m; remove quotes surrounding your string\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 82\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: '' is not a valid value for backend; supported values are ['GTK3Agg', 'GTK3Cairo', 'GTK4Agg', 'GTK4Cairo', 'MacOSX', 'nbAgg', 'QtAgg', 'QtCairo', 'Qt5Agg', 'Qt5Cairo', 'TkAgg', 'TkCairo', 'WebAgg', 'WX', 'WXAgg', 'WXCairo', 'agg', 'cairo', 'pdf', 'pgf', 'ps', 'svg', 'template']"
     ]
    }
   ],
   "source": [
    "matplotlib.use('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> 8ffa19d78399140cf9b0d67ddc52cb34a0064e98
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "293c9fda8fcd90de8c2a1fae410c9ec63949f59bfdddf3c59dafd28380957ee9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
